{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphi\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immutables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../data/raw/\"\n",
    "SAMPLE_DATA_FILE = \"split2250_bipolarRerefType1_lineNoiseRemoved_postPuffpreStim.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLY_DATA = sio.loadmat(RAW_DATA_DIR + SAMPLE_DATA_FILE).get(\"fly_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_log_reg(data):\n",
    "    \"\"\" Generate logistic regression for binarised past and present states.\n",
    "    \n",
    "    Args:\n",
    "        data (array): (timepoints, channels, trials) array of binarised data.\n",
    "                      The data will pool each timepoint step as a separate trial.\n",
    "                      \n",
    "    Returns: \n",
    "        List of Logistic regressions (fitted) for each channel.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_timepoints, n_channels, n_trials = data.shape\n",
    "    \n",
    "    samples = np.zeros((n_channels * 2, (n_trials * (n_timepoints - 1))))\n",
    "    \n",
    "    for i_p in range(n_timepoints - 1):\n",
    "        sliced = data[i_p:i_p+2, :, :]\n",
    "        new_sample = sliced.reshape((n_channels * 2, n_trials))\n",
    "        samples[:, i_p * n_trials:(i_p+1)*n_trials] = new_sample\n",
    "    \n",
    "    X = samples[0:n_channels, :].transpose()\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for i_c in range(n_channels):\n",
    "        y = samples[n_channels + i_c]\n",
    "        lr = LogisticRegression(solver='lbfgs')\n",
    "        model = lr.fit(X, y)\n",
    "        models.append(model)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_to_tpm(models, n_channels):\n",
    "    \"\"\" Converts a logistic regression model to a TPM\n",
    "    \n",
    "    Args:\n",
    "        models: List of fitted logistic regression models.\n",
    "        n_channels (int): Number of channels used to generate model.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array as a TPM.\n",
    "    \"\"\"\n",
    "    \n",
    "    tpm_shape = [2] * n_channels + [n_channels]\n",
    "    \n",
    "    tpm = np.zeros(tpm_shape)\n",
    "    \n",
    "    for state in itertools.product((0, 1), repeat=n_channels):\n",
    "        for i_m, model in enumerate(models):\n",
    "            tpm[state + (i_m,)] = model.predict_proba(np.array([state]))[0][1]\n",
    "    \n",
    "    return tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpm_log_reg(data):\n",
    "    \"\"\" Generate tpm using log regression for binarised past and present states.\n",
    "    \n",
    "    Args:\n",
    "        data (array): (timepoints, channels, trials) array of binarised data.\n",
    "                      The data will pool each timepoint step as a separate trial.\n",
    "                      \n",
    "    Returns: \n",
    "        TPM for the input data.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, n_channels, _ = data.shape\n",
    "    \n",
    "    return models_to_tpm(gen_log_reg(data), n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_generate(tpm, n_timepoints, n_channels):\n",
    "    \n",
    "    states = list(itertools.product((0, 1), repeat=n_channels))\n",
    "    \n",
    "    samples = np.zeros((1 + n_timepoints, n_channels, (2 ** n_channels) * 10))\n",
    "    \n",
    "    for i_s, state in enumerate(states * 10):\n",
    "        samples[0, :, i_s] = np.array(state)\n",
    "        \n",
    "        for i_t in range(n_timepoints):\n",
    "            curr_state = tuple(samples[i_t, :, i_s].astype(int))\n",
    "            value = tpm[curr_state]\n",
    "            samples[i_t + 1, :, i_s] = value\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shape = [2] * 3 + [3]\n",
    "test_tpm = np.zeros(test_shape)\n",
    "\"\"\"\n",
    "test_tpm[(0, 0, 0)] = np.array([0, 0, 0])\n",
    "test_tpm[(1, 0, 0)] = np.array([0, 0, 1])\n",
    "test_tpm[(0, 1, 0)] = np.array([1, 0, 1])\n",
    "test_tpm[(1, 1, 0)] = np.array([1, 0, 0])\n",
    "test_tpm[(0, 0, 1)] = np.array([1, 1, 0])\n",
    "test_tpm[(1, 0, 1)] = np.array([1, 1, 1])\n",
    "test_tpm[(0, 1, 1)] = np.array([1, 1, 1])\n",
    "test_tpm[(1, 1, 1)] = np.array([1, 1, 0])\n",
    "\"\"\"\n",
    "test_tpm[(0, 0, 0)] = np.array([0, 1, 0])\n",
    "test_tpm[(1, 0, 0)] = np.array([1, 0, 0])\n",
    "test_tpm[(0, 1, 0)] = np.array([1, 1, 1])\n",
    "test_tpm[(1, 1, 0)] = np.array([1, 0, 1])\n",
    "test_tpm[(0, 0, 1)] = np.array([1, 1, 0])\n",
    "test_tpm[(1, 0, 1)] = np.array([1, 1, 1])\n",
    "test_tpm[(0, 1, 1)] = np.array([0, 1, 0])\n",
    "test_tpm[(1, 1, 1)] = np.array([1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = det_generate(test_tpm, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "out_tpm = tpm_log_reg(test_samples).round(decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE = (0, 0, 0), IN_TPM = [0. 1. 0.], OUT_TPM = [1. 1. 0.]\n",
      "STATE = (0, 0, 1), IN_TPM = [1. 1. 0.], OUT_TPM = [1. 1. 0.]\n",
      "STATE = (0, 1, 0), IN_TPM = [1. 1. 1.], OUT_TPM = [1. 1. 1.]\n",
      "STATE = (0, 1, 1), IN_TPM = [0. 1. 0.], OUT_TPM = [1. 1. 1.]\n",
      "STATE = (1, 0, 0), IN_TPM = [1. 0. 0.], OUT_TPM = [1. 0. 0.]\n",
      "STATE = (1, 0, 1), IN_TPM = [1. 1. 1.], OUT_TPM = [1. 0. 0.]\n",
      "STATE = (1, 1, 0), IN_TPM = [1. 0. 1.], OUT_TPM = [1. 0. 0.]\n",
      "STATE = (1, 1, 1), IN_TPM = [1. 0. 0.], OUT_TPM = [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for state in itertools.product((0, 1), repeat=3):\n",
    "    print(\"STATE = {}, IN_TPM = {}, OUT_TPM = {}\".format(state, \n",
    "                                                         test_tpm[state], \n",
    "                                                         out_tpm[state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250, 15, 8, 13, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLY_DATA.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
