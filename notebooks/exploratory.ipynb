{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphi\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import patsy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immutables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"../data/raw/\"\n",
    "SAMPLE_DATA_FILE = \"split2250_bipolarRerefType1_lineNoiseRemoved_postPuffpreStim.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLY_DATA = sio.loadmat(RAW_DATA_DIR + SAMPLE_DATA_FILE).get(\"fly_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_log_reg(data):\n",
    "    \"\"\" Generate logistic regression for binarised past and present states.\n",
    "    \n",
    "    Args:\n",
    "        data (array): (timepoints, channels, trials) array of binarised data.\n",
    "                      The data will pool each timepoint step as a separate trial.\n",
    "                      \n",
    "    Returns: \n",
    "        List of Logistic regressions (fitted) for each channel.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_timepoints, n_channels, n_trials = data.shape\n",
    "    \n",
    "    samples = np.zeros((n_channels * 2, (n_trials * (n_timepoints - 1))))\n",
    "    \n",
    "    for i_p in range(n_timepoints - 1):\n",
    "        sliced = data[i_p:i_p+2, :, :]\n",
    "        new_sample = sliced.reshape((n_channels * 2, n_trials))\n",
    "        samples[:, i_p * n_trials:(i_p+1)*n_trials] = new_sample\n",
    "    \n",
    "    #X = samples[0:n_channels, :].transpose()\n",
    "    \n",
    "    # TODO find faster way to construct dict\n",
    "    data_dict = {\"x{}\".format(i_x): samples[i_x] for \\\n",
    "                i_x in range(n_channels)}\n",
    "    \n",
    "    patsy_str = \"*\".join([\"x{}\".format(i_x) for i_x in range(n_channels)])\n",
    "    \n",
    "    X_dmatrix = patsy.dmatrix(patsy_str, data_dict)\n",
    "    Xs = X_dmatrix[:, 1:] # exclude intercept term\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for i_c in range(n_channels):\n",
    "        y = samples[n_channels + i_c]\n",
    "        lr = LogisticRegression(solver='lbfgs')\n",
    "        model = lr.fit(Xs, y)\n",
    "        models.append(model)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_to_tpm(models, n_channels):\n",
    "    \"\"\" Converts a logistic regression model to a TPM\n",
    "    \n",
    "    Args:\n",
    "        models: List of fitted logistic regression models.\n",
    "        n_channels (int): Number of channels used to generate model.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array as a TPM.\n",
    "    \"\"\"\n",
    "    \n",
    "    tpm_shape = [2] * n_channels + [n_channels]\n",
    "    \n",
    "    tpm = np.zeros(tpm_shape)\n",
    "    \n",
    "    for state in itertools.product((0, 1), repeat=n_channels):\n",
    "        for i_m, model in enumerate(models):\n",
    "            state_arr = np.array(state)\n",
    "            data_dict = {\"x{}\".format(i_x): state_arr[i_x] for \\\n",
    "                        i_x in range(n_channels)}\n",
    "            patsy_str = \"*\".join([\"x{}\".format(i_x) for i_x in range(n_channels)])\n",
    "            state_dmatrix = patsy.dmatrix(patsy_str, data_dict)\n",
    "            state_interact = state_dmatrix[:, 1:]\n",
    "            tpm[state + (i_m,)] = model.predict_proba(state_interact)[0][1]\n",
    "    \n",
    "    return tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpm_log_reg(data):\n",
    "    \"\"\" Generate tpm using log regression for binarised past and present states.\n",
    "    \n",
    "    Args:\n",
    "        data (array): (timepoints, channels, trials) array of binarised data.\n",
    "                      The data will pool each timepoint step as a separate trial.\n",
    "                      \n",
    "    Returns: \n",
    "        TPM for the input data.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, n_channels, _ = data.shape\n",
    "    \n",
    "    return models_to_tpm(gen_log_reg(data), n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data (Deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_generate(tpm, n_timepoints, n_channels, n_trials):\n",
    "    \n",
    "    states = list(itertools.product((0, 1), repeat=n_channels))\n",
    "    \n",
    "    samples = np.zeros((1 + n_timepoints, n_channels, (2 ** n_channels) * n_trials))\n",
    "    \n",
    "    for i_s, state in enumerate(states * n_trials):\n",
    "        samples[0, :, i_s] = np.array(state)\n",
    "        \n",
    "        for i_t in range(n_timepoints):\n",
    "            curr_state = tuple(samples[i_t, :, i_s].astype(int))\n",
    "            value = tpm[curr_state]\n",
    "            samples[i_t + 1, :, i_s] = value\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shape = [2] * 3 + [3]\n",
    "test_tpm = np.zeros(test_shape)\n",
    "\n",
    "test_tpm[(0, 0, 0)] = np.array([0, 0, 0])\n",
    "test_tpm[(1, 0, 0)] = np.array([0, 0, 1])\n",
    "test_tpm[(0, 1, 0)] = np.array([1, 0, 1])\n",
    "test_tpm[(1, 1, 0)] = np.array([1, 0, 0])\n",
    "test_tpm[(0, 0, 1)] = np.array([1, 1, 0])\n",
    "test_tpm[(1, 0, 1)] = np.array([1, 1, 1])\n",
    "test_tpm[(0, 1, 1)] = np.array([1, 1, 1])\n",
    "test_tpm[(1, 1, 1)] = np.array([1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_10_trials = det_generate(test_tpm, 100, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "out_tpm_10_trials = tpm_log_reg(test_samples_10_trials).round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE = (0, 0, 0), IN_TPM = [0. 0. 0.], OUT_TPM = [0. 0. 0.]\n",
      "STATE = (0, 0, 1), IN_TPM = [1. 1. 0.], OUT_TPM = [1. 1. 0.]\n",
      "STATE = (0, 1, 0), IN_TPM = [1. 0. 1.], OUT_TPM = [0.9 0.  0.1]\n",
      "STATE = (0, 1, 1), IN_TPM = [1. 1. 1.], OUT_TPM = [1.  1.  0.5]\n",
      "STATE = (1, 0, 0), IN_TPM = [0. 0. 1.], OUT_TPM = [0. 0. 1.]\n",
      "STATE = (1, 0, 1), IN_TPM = [1. 1. 1.], OUT_TPM = [1. 1. 1.]\n",
      "STATE = (1, 1, 0), IN_TPM = [1. 0. 0.], OUT_TPM = [1. 0. 0.]\n",
      "STATE = (1, 1, 1), IN_TPM = [1. 1. 0.], OUT_TPM = [1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for state in itertools.product((0, 1), repeat=3):\n",
    "    print(\"STATE = {}, IN_TPM = {}, OUT_TPM = {}\".format(state, \n",
    "                                                         test_tpm[state], \n",
    "                                                         out_tpm_10_trials[state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_50_trials = det_generate(test_tpm, 100, 3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tpm_50_trials = tpm_log_reg(test_samples_50_trials).round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE = (0, 0, 0), IN_TPM = [0. 0. 0.], OUT_TPM = [0. 0. 0.]\n",
      "STATE = (0, 0, 1), IN_TPM = [1. 1. 0.], OUT_TPM = [1. 1. 0.]\n",
      "STATE = (0, 1, 0), IN_TPM = [1. 0. 1.], OUT_TPM = [0.9 0.  0.6]\n",
      "STATE = (0, 1, 1), IN_TPM = [1. 1. 1.], OUT_TPM = [1.  1.  0.9]\n",
      "STATE = (1, 0, 0), IN_TPM = [0. 0. 1.], OUT_TPM = [0. 0. 1.]\n",
      "STATE = (1, 0, 1), IN_TPM = [1. 1. 1.], OUT_TPM = [1. 1. 1.]\n",
      "STATE = (1, 1, 0), IN_TPM = [1. 0. 0.], OUT_TPM = [1. 0. 0.]\n",
      "STATE = (1, 1, 1), IN_TPM = [1. 1. 0.], OUT_TPM = [1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for state in itertools.product((0, 1), repeat=3):\n",
    "    print(\"STATE = {}, IN_TPM = {}, OUT_TPM = {}\".format(state, \n",
    "                                                         test_tpm[state], \n",
    "                                                         out_tpm_50_trials[state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As a note, it seems when the number of trials is low and a certain state does not occur frequently, the transition probability from that state is quite poorly estimated (as can be seen from the comparison from 10 trials and 50 trials above). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLY_DATA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the data corresponds to:\n",
    "\n",
    "- 2350 time samples (at 1000Hz)\n",
    "- 15 channels (bipolar re-referenced)\n",
    "- 8 \"trials\" (from one trial cut into smaller trials)\n",
    "- 13 flies\n",
    "- 2 conditions (awake and anaesthetised respectively)\n",
    "\n",
    "The reference paper is at https://doi.org/10.1523/ENEURO.0329-17.2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
